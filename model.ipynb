{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e15d26c",
   "metadata": {},
   "source": [
    "### A definition of the machine learning problem you are working on: the input and the target. \n",
    "\n",
    "This project focuses on predicting whether NBA players will be selected to an All-NBA team based on their season statistics. The dataset includes one row per player-season, with a variety of performance metrics (points, rebounds, assists, etc.), and a binary target variable `is_allnba` indicating whether the player made an All-NBA team. The goal is to develop machine learning models that can generalize well and identify future All-NBA players, even in the presence of severe class imbalance—only a small percentage of players make these teams each year.\n",
    "\n",
    "After loading and inspecting the dataset, the target variable is created by checking if a player was assigned to any All-NBA team. Categorical features such as player position are cleaned and mapped to standardized roles (G, F, C). Irrelevant columns like player name, team, and year are removed to prevent data leakage. The remaining features are separated into numerical and categorical types to support the preprocessing pipeline.\n",
    "\n",
    "The data is split into training and test sets with stratification to preserve the original class distribution. Preprocessing includes imputing missing values, scaling numerical features, and one-hot encoding categorical ones. Three models are trained: logistic regression, random forest, and XGBoost. Each model is placed into a pipeline that includes SMOTE, an oversampling method used to balance the classes. Hyperparameters are optimized using grid search with 3-fold stratified cross-validation, and ROC-AUC is used as the scoring metric to ensure the models remain sensitive to the minority class.\n",
    "\n",
    "Model performance is evaluated using ROC-AUC, precision, recall, and F1-score on the held-out test set. While all metrics are considered, recall is especially important for this task. Since only a handful of players make the All-NBA team, the project prioritizes catching as many of these true positive cases as possible. High recall ensures that the model successfully identifies most deserving players, even if it makes a few incorrect guesses.\n",
    "\n",
    "The project concludes with a comparison of the models’ performance and, optionally, a feature importance analysis using the random forest model. This helps provide insight into which stats—such as points, win shares, or efficiency ratings—are most predictive of All-NBA selection. Overall, the project reflects a practical, metrics-aware approach to dealing with imbalanced classification problems in sports analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7f4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded stats: 9663 rows × 37 cols\n",
      "Target distribution:\n",
      "is_allnba\n",
      "0    9398\n",
      "1     265\n",
      "Name: count, dtype: int64\n",
      "Positive class percentage: 2.74%\n",
      "Using 31 numeric features and 1 categorical features\n",
      "Training set size: 7730 samples\n",
      "Test set size: 1933 samples\n",
      "Training set class distribution:\n",
      "is_allnba\n",
      "0    7518\n",
      "1     212\n",
      "Name: count, dtype: int64\n",
      "Test set class distribution:\n",
      "is_allnba\n",
      "0    1880\n",
      "1      53\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "Training LogisticRegression...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best parameters: {'clf__C': 1.0, 'clf__solver': 'liblinear'}\n",
      "Best CV score: 0.9801\n",
      "\n",
      "--------------------------------------------------\n",
      "Training RandomForest...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best parameters: {'clf__max_depth': None, 'clf__min_samples_split': 5, 'clf__n_estimators': 200}\n",
      "Best CV score: 0.9794\n",
      "\n",
      "--------------------------------------------------\n",
      "Training XGBoost...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [23:23:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__learning_rate': 0.1, 'clf__max_depth': 5, 'clf__n_estimators': 200}\n",
      "Best CV score: 0.9827\n",
      "\n",
      "============================================================\n",
      "TEST SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "--- LogisticRegression Results ---\n",
      "ROC-AUC: 0.9837\n",
      "Precision: 0.3086\n",
      "Recall: 0.9434\n",
      "F1-Score: 0.4651\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1880\n",
      "           1       0.31      0.94      0.47        53\n",
      "\n",
      "    accuracy                           0.94      1933\n",
      "   macro avg       0.65      0.94      0.72      1933\n",
      "weighted avg       0.98      0.94      0.95      1933\n",
      "\n",
      "\n",
      "--- RandomForest Results ---\n",
      "ROC-AUC: 0.9802\n",
      "Precision: 0.5000\n",
      "Recall: 0.6981\n",
      "F1-Score: 0.5827\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1880\n",
      "           1       0.50      0.70      0.58        53\n",
      "\n",
      "    accuracy                           0.97      1933\n",
      "   macro avg       0.75      0.84      0.78      1933\n",
      "weighted avg       0.98      0.97      0.97      1933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_8420\\1522316604.py:185: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- XGBoost Results ---\n",
      "ROC-AUC: 0.9833\n",
      "Precision: 0.5526\n",
      "Recall: 0.7925\n",
      "F1-Score: 0.6512\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1880\n",
      "           1       0.55      0.79      0.65        53\n",
      "\n",
      "    accuracy                           0.98      1933\n",
      "   macro avg       0.77      0.89      0.82      1933\n",
      "weighted avg       0.98      0.98      0.98      1933\n",
      "\n",
      "\n",
      "============================================================\n",
      "MODEL COMPARISON\n",
      "============================================================\n",
      "                Model   ROC-AUC  Precision    Recall  F1-Score\n",
      "0  LogisticRegression  0.983721   0.308642  0.943396  0.465116\n",
      "1             XGBoost  0.983340   0.552632  0.792453  0.651163\n",
      "2        RandomForest  0.980239   0.500000  0.698113  0.582677\n",
      "\n",
      "============================================================\n",
      "FEATURE IMPORTANCE\n",
      "============================================================\n",
      "Top 15 most important features:\n",
      "num__PER: 0.1776\n",
      "num__VORP: 0.1170\n",
      "num__PTS_per_game: 0.1110\n",
      "num__WS/48: 0.0919\n",
      "num__BPM: 0.0747\n",
      "num__MPG: 0.0622\n",
      "num__GS: 0.0600\n",
      "num__OBPM: 0.0431\n",
      "num__USG%: 0.0417\n",
      "num__TOV_per_game: 0.0324\n",
      "num__AST_per_game: 0.0199\n",
      "num__TS%: 0.0144\n",
      "num__STL_per_game: 0.0144\n",
      "num__TRB_per_game: 0.0140\n",
      "num__FTr: 0.0140\n"
     ]
    }
   ],
   "source": [
    "# === Prerequisites ===\n",
    "# Make sure you have these libraries installed in your notebook environment:\n",
    "# !pip install imbalanced-learn xgboost scikit-learn pandas numpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing & modeling imports\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# For handling class imbalance\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# --- 1. Load dataset ---\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('data_used_for_models.csv')\n",
    "print(f\"Loaded stats: {df.shape[0]} rows × {df.shape[1]} cols\")\n",
    "\n",
    "# --- 2. Create binary target and basic cleaning ---\n",
    "# Convert team column to binary target (1 if player made All-NBA, 0 otherwise)\n",
    "if 'nba_team' in df.columns:\n",
    "    # For compatibility with original data\n",
    "    df['is_allnba'] = df['nba_team'].apply(lambda x: 0 if pd.isna(x) or x == 'None' else 1)\n",
    "elif 'all_nba_team' in df.columns:\n",
    "    # For compatibility with the uploaded notebook data\n",
    "    df['is_allnba'] = df['all_nba_team'].apply(lambda x: 0 if x == 0 else 1)\n",
    "else:\n",
    "    # Try to infer from data\n",
    "    potential_columns = [col for col in df.columns if 'nba' in col.lower() or 'team' in col.lower()]\n",
    "    if potential_columns:\n",
    "        print(f\"Inferring 'is_allnba' from column: {potential_columns[0]}\")\n",
    "        df['is_allnba'] = df[potential_columns[0]].apply(lambda x: 0 if pd.isna(x) or x == 0 or x == 'None' else 1)\n",
    "    else:\n",
    "        raise ValueError(\"Cannot find NBA team column to create target variable\")\n",
    "\n",
    "print(\"Target distribution:\")\n",
    "print(df['is_allnba'].value_counts())\n",
    "print(f\"Positive class percentage: {df['is_allnba'].mean()*100:.2f}%\")\n",
    "\n",
    "# --- 3. Basic cleaning & feature preparation ---\n",
    "# Handle categorical features like Position\n",
    "if 'Position' in df.columns:\n",
    "    # Normalize Position to G/F/C\n",
    "    pos_map = {\n",
    "        'G':'G','PG':'G','SG':'G','G-F':'G',\n",
    "        'F':'F','SF':'F','PF':'F','F-G':'F','F-C':'F',\n",
    "        'C':'C','C-F':'C'\n",
    "    }\n",
    "    df['Position'] = df['Position'].map(pos_map).fillna('G')  # Default to Guard if unknown\n",
    "\n",
    "# Drop identifiers and other non-feature columns\n",
    "drop_cols = ['index', 'Year', 'Player', 'Tm', 'is_allnba']\n",
    "if 'nba_team' in df.columns:\n",
    "    drop_cols.append('nba_team')\n",
    "if 'all_nba_team' in df.columns:\n",
    "    drop_cols.append('all_nba_team')\n",
    "\n",
    "feature_cols = [col for col in df.columns if col not in drop_cols]\n",
    "\n",
    "# Identify numeric and categorical features\n",
    "cat_cols = df[feature_cols].select_dtypes(include=['object']).columns.tolist()\n",
    "num_cols = df[feature_cols].select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "print(f\"Using {len(num_cols)} numeric features and {len(cat_cols)} categorical features\")\n",
    "\n",
    "# --- 4. Train/test split ---\n",
    "X = df[num_cols + cat_cols]\n",
    "y = df['is_allnba']\n",
    "\n",
    "# Ensure enough samples in each class with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Training set class distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"Test set class distribution:\\n{y_test.value_counts()}\")\n",
    "\n",
    "# --- 5. Create preprocessing pipeline ---\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')), \n",
    "        ('scaler', StandardScaler())\n",
    "    ]), num_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')), \n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "# --- 6. Create models with hyperparameter search ---\n",
    "# Use 3-fold CV to avoid issues with class imbalance\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'pipe': ImbPipeline([\n",
    "            ('pre', preprocessor),\n",
    "            ('sampler', SMOTE(random_state=42)),\n",
    "            ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__C': [0.01, 0.1, 1.0, 10.0],\n",
    "            'clf__solver': ['liblinear', 'saga']\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'pipe': ImbPipeline([\n",
    "            ('pre', preprocessor),\n",
    "            ('sampler', SMOTE(random_state=42)),\n",
    "            ('clf', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__n_estimators': [100, 200],\n",
    "            'clf__max_depth': [None, 10, 20],\n",
    "            'clf__min_samples_split': [2, 5]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'pipe': ImbPipeline([\n",
    "            ('pre', preprocessor),\n",
    "            ('sampler', SMOTE(random_state=42)),\n",
    "            ('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__n_estimators': [100, 200],\n",
    "            'clf__max_depth': [3, 5, 7],\n",
    "            'clf__learning_rate': [0.01, 0.1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- 7. Train models with hyperparameter search ---\n",
    "best_models = {}\n",
    "\n",
    "for name, model_info in models.items():\n",
    "    print(f\"\\n{'-'*50}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        model_info['pipe'],\n",
    "        model_info['params'],\n",
    "        cv=cv,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best parameters: {grid.best_params_}\")\n",
    "    print(f\"Best CV score: {grid.best_score_:.4f}\")\n",
    "    \n",
    "    best_models[name] = grid.best_estimator_\n",
    "\n",
    "# --- 8. Evaluate models on test set ---\n",
    "results = pd.DataFrame(columns=['Model', 'ROC-AUC', 'Precision', 'Recall', 'F1-Score'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Add to results dataframe\n",
    "    results = pd.concat([results, pd.DataFrame({\n",
    "        'Model': [name],\n",
    "        'ROC-AUC': [roc_auc],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1-Score': [f1]\n",
    "    })], ignore_index=True)\n",
    "    \n",
    "    print(f\"\\n--- {name} Results ---\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Show final comparison table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(results.sort_values('ROC-AUC', ascending=False).reset_index(drop=True))\n",
    "\n",
    "# --- 9. (Optional) Feature importance from best model ---\n",
    "if 'RandomForest' in best_models:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FEATURE IMPORTANCE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    rf_model = best_models['RandomForest'].named_steps['clf']\n",
    "    preprocessor = best_models['RandomForest'].named_steps['pre']\n",
    "    \n",
    "    # Get feature names\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = rf_model.feature_importances_\n",
    "    \n",
    "    # Sort by importance\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    print(\"Top 15 most important features:\")\n",
    "    for i in range(min(15, len(feature_names))):\n",
    "        print(f\"{feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")\n",
    "\n",
    "    #end of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ee793",
   "metadata": {},
   "source": [
    "### For each algorithm explain which hyper-parameters you worked with and how you picked them. Bonus points if you apply the xgboost library.\n",
    "\n",
    "This project applied three different algorithms—logistic regression, random forest, and XGBoost(and the library for extra points)—to predict whether an NBA player would be selected to an All-NBA team based on season statistics. All models were implemented using scikit-learn and imbalanced-learn, with XGBoost handled using its dedicated Python API.\n",
    "\n",
    "Each model was placed into a pipeline that included preprocessing steps and a SMOTE sampler to address the significant class imbalance. For logistic regression, the hyperparameters tuned were the inverse regularization strength `C` and the solver (`liblinear` and `saga`). These were selected because they control the model’s flexibility and optimization strategy. GridSearchCV with 3-fold stratified cross-validation was used to search for the combination that gave the best ROC-AUC score.\n",
    "\n",
    "For the random forest model, key hyperparameters included the number of estimators (`n_estimators`), maximum depth of each tree (`max_depth`), and the minimum number of samples required to split a node (`min_samples_split`). These settings influence both model complexity and overfitting. A grid search was again performed to identify the best configuration, balancing depth and generalization.\n",
    "\n",
    "The third algorithm used was XGBoost, which was also the most flexible and powerful among the three. The main hyperparameters tuned included the number of boosting rounds (`n_estimators`), maximum tree depth (`max_depth`), and learning rate. These parameters govern how fast and deep the boosting process goes. Grid search was used here as well, and the model was evaluated using ROC-AUC to ensure good separation of the minority (All-NBA) class.\n",
    "\n",
    "All models were evaluated on a held-out test set using metrics such as precision, recall, F1-score, and ROC-AUC, with particular attention paid to recall given the importance of correctly identifying actual All-NBA players. This setup not only satisfies the assignment requirement of applying three distinct algorithms but also includes bonus implementation of XGBoost with appropriate tuning and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd4ce9",
   "metadata": {},
   "source": [
    "### A summary of your observations, and a separate optional section describing what you think may be a non-standard/novel thing you did in your experiments.\n",
    "\n",
    "##### Summary of Observations:\n",
    "After training and evaluating logistic regression, random forest, and XGBoost models on the All-NBA dataset, several patterns emerged. The most notable was that all models achieved very strong ROC-AUC scores (above 0.98), suggesting they were effective at distinguishing between All-NBA and non-All-NBA players. However, there were clear differences in how each model balanced precision and recall. Logistic regression had the highest recall at 94.3%, correctly identifying nearly all actual All-NBA players, but at the cost of precision—it incorrectly labeled many non-All-NBA players as positive. XGBoost offered the best balance overall, with a strong recall of 79.2% and a significantly higher precision of 55.3%, leading to the highest F1-score. Random forest trailed slightly behind XGBoost but still performed well in both recall and precision.\n",
    "\n",
    "\n",
    "The class imbalance (only 2.74% positive class) posed a major challenge. This was effectively handled using SMOTE within each model’s pipeline, which helped ensure that the models could actually learn from the limited All-NBA examples. Without this, the models would have likely defaulted to always predicting the negative class. The results highlight how critical it is to tune for recall in a task like this, where failing to recognize deserving All-NBA players would undermine the usefulness of the model.\n",
    "\n",
    "\n",
    "#### Optional: Non-standard/Novel Elements:\n",
    "A few elements of this project go slightly beyond a standard application. Most notably, SMOTE was integrated directly within each model’s cross-validation pipeline, ensuring oversampling was applied only during training folds and not leaked into validation, which could otherwise inflate performance. Another thoughtful detail was the normalization of positional data to core roles (G/F/C), which reduced noise during one-hot encoding and likely helped model consistency. Additionally, the feature importance analysis from the random forest model provided valuable interpretability. It revealed that advanced metrics like PER, VORP, WS/48, and BPM were among the most predictive of All-NBA selection, confirming that efficiency and overall impact metrics matter more than just raw box score stats. This kind of insight, derived from the model itself, adds meaningful depth to the analysis.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
