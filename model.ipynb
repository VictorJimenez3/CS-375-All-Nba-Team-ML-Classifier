{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e15d26c",
   "metadata": {},
   "source": [
    "### A definition of the machine learning problem you are working on: the input and the target. \n",
    "\n",
    "This project focuses on predicting whether NBA players will be selected to an All-NBA team based on their season statistics. The dataset includes one row per player-season, with a variety of performance metrics (points, rebounds, assists, etc.), and a binary target variable `is_allnba` indicating whether the player made an All-NBA team. The goal is to develop machine learning models that can generalize well and identify future All-NBA players, even in the presence of severe class imbalance—only a small percentage of players make these teams each year.\n",
    "\n",
    "After loading and inspecting the dataset, the target variable is created by checking if a player was assigned to any All-NBA team. Categorical features such as player position are cleaned and mapped to standardized roles (G, F, C). Irrelevant columns like player name, team, and year are removed to prevent data leakage. The remaining features are separated into numerical and categorical types to support the preprocessing pipeline.\n",
    "\n",
    "The data is split into training and test sets with stratification to preserve the original class distribution. Preprocessing includes imputing missing values, scaling numerical features, and one-hot encoding categorical ones. Three models are trained: logistic regression, random forest, and XGBoost. Each model is placed into a pipeline that includes SMOTE, an oversampling method used to balance the classes. Hyperparameters are optimized using grid search with 3-fold stratified cross-validation, and ROC-AUC is used as the scoring metric to ensure the models remain sensitive to the minority class.\n",
    "\n",
    "Model performance is evaluated using ROC-AUC, precision, recall, and F1-score on the held-out test set. While all metrics are considered, recall is especially important for this task. Since only a handful of players make the All-NBA team, the project prioritizes catching as many of these true positive cases as possible. High recall ensures that the model successfully identifies most deserving players, even if it makes a few incorrect guesses.\n",
    "\n",
    "The project concludes with a comparison of the models’ performance and, optionally, a feature importance analysis using the random forest model. This helps provide insight into which stats—such as points, win shares, or efficiency ratings—are most predictive of All-NBA selection. Overall, the project reflects a practical, metrics-aware approach to dealing with imbalanced classification problems in sports analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc7f4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded stats: 9663 rows × 37 cols\n",
      "Target distribution:\n",
      "is_allnba\n",
      "0    9398\n",
      "1     265\n",
      "Name: count, dtype: int64\n",
      "Positive class percentage: 2.74%\n",
      "Using 31 numeric features and 1 categorical features\n",
      "Training set size: 7730 samples\n",
      "Test set size: 1933 samples\n",
      "Training set class distribution:\n",
      "is_allnba\n",
      "0    7518\n",
      "1     212\n",
      "Name: count, dtype: int64\n",
      "Test set class distribution:\n",
      "is_allnba\n",
      "0    1880\n",
      "1      53\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "Training LogisticRegression...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTerminatedWorkerError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 160\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    151\u001b[39m grid = GridSearchCV(\n\u001b[32m    152\u001b[39m     model_info[\u001b[33m'\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    153\u001b[39m     model_info[\u001b[33m'\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    157\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m    158\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    163\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest CV score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid.best_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1754\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1748\u001b[39m \n\u001b[32m   1749\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1752\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1754\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1755\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1757\u001b[39m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1789\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1785\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1789\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:745\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    739\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    742\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    743\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    744\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:763\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    762\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mTerminatedWorkerError\u001b[39m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n"
     ]
    }
   ],
   "source": [
    "# === Prerequisites ===\n",
    "# Make sure you have these libraries installed in your notebook environment:\n",
    "# !pip install imbalanced-learn xgboost scikit-learn pandas numpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing & modeling imports\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# For handling class imbalance\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# --- 1. Load dataset ---\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('data_used_for_models.csv')\n",
    "print(f\"Loaded stats: {df.shape[0]} rows × {df.shape[1]} cols\")\n",
    "\n",
    "# --- 2. Create binary target and basic cleaning ---\n",
    "# Convert team column to binary target (1 if player made All-NBA, 0 otherwise)\n",
    "if 'nba_team' in df.columns:\n",
    "    # For compatibility with original data\n",
    "    df['is_allnba'] = df['nba_team'].apply(lambda x: 0 if pd.isna(x) or x == 'None' else 1)\n",
    "elif 'all_nba_team' in df.columns:\n",
    "    # For compatibility with the uploaded notebook data\n",
    "    df['is_allnba'] = df['all_nba_team'].apply(lambda x: 0 if x == 0 else 1)\n",
    "else:\n",
    "    # Try to infer from data\n",
    "    potential_columns = [col for col in df.columns if 'nba' in col.lower() or 'team' in col.lower()]\n",
    "    if potential_columns:\n",
    "        print(f\"Inferring 'is_allnba' from column: {potential_columns[0]}\")\n",
    "        df['is_allnba'] = df[potential_columns[0]].apply(lambda x: 0 if pd.isna(x) or x == 0 or x == 'None' else 1)\n",
    "    else:\n",
    "        raise ValueError(\"Cannot find NBA team column to create target variable\")\n",
    "\n",
    "print(\"Target distribution:\")\n",
    "print(df['is_allnba'].value_counts())\n",
    "print(f\"Positive class percentage: {df['is_allnba'].mean()*100:.2f}%\")\n",
    "\n",
    "# --- 3. Basic cleaning & feature preparation ---\n",
    "# Handle categorical features like Position\n",
    "if 'Position' in df.columns:\n",
    "    # Normalize Position to G/F/C\n",
    "    pos_map = {\n",
    "        'G':'G','PG':'G','SG':'G','G-F':'G',\n",
    "        'F':'F','SF':'F','PF':'F','F-G':'F','F-C':'F',\n",
    "        'C':'C','C-F':'C'\n",
    "    }\n",
    "    df['Position'] = df['Position'].map(pos_map).fillna('G')  # Default to Guard if unknown\n",
    "\n",
    "# Drop identifiers and other non-feature columns\n",
    "drop_cols = ['index', 'Year', 'Player', 'Tm', 'is_allnba']\n",
    "if 'nba_team' in df.columns:\n",
    "    drop_cols.append('nba_team')\n",
    "if 'all_nba_team' in df.columns:\n",
    "    drop_cols.append('all_nba_team')\n",
    "\n",
    "feature_cols = [col for col in df.columns if col not in drop_cols]\n",
    "\n",
    "# Identify numeric and categorical features\n",
    "cat_cols = df[feature_cols].select_dtypes(include=['object']).columns.tolist()\n",
    "num_cols = df[feature_cols].select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "print(f\"Using {len(num_cols)} numeric features and {len(cat_cols)} categorical features\")\n",
    "\n",
    "# --- 4. Train/test split ---\n",
    "X = df[num_cols + cat_cols]\n",
    "y = df['is_allnba']\n",
    "\n",
    "# Ensure enough samples in each class with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Training set class distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"Test set class distribution:\\n{y_test.value_counts()}\")\n",
    "\n",
    "# --- 5. Create preprocessing pipeline ---\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')), \n",
    "        ('scaler', StandardScaler())\n",
    "    ]), num_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')), \n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "# --- 6. Create models with hyperparameter search ---\n",
    "# Use 3-fold CV to avoid issues with class imbalance\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'pipe': ImbPipeline([\n",
    "            ('pre', preprocessor),\n",
    "            ('sampler', SMOTE(random_state=42)),\n",
    "            ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__C': [0.01, 0.1, 1.0, 10.0],\n",
    "            'clf__solver': ['liblinear', 'saga']\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'pipe': ImbPipeline([\n",
    "            ('pre', preprocessor),\n",
    "            ('sampler', SMOTE(random_state=42)),\n",
    "            ('clf', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__n_estimators': [100, 200],\n",
    "            'clf__max_depth': [None, 10, 20],\n",
    "            'clf__min_samples_split': [2, 5]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'pipe': ImbPipeline([\n",
    "            ('pre', preprocessor),\n",
    "            ('sampler', SMOTE(random_state=42)),\n",
    "            ('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__n_estimators': [100, 200],\n",
    "            'clf__max_depth': [3, 5, 7],\n",
    "            'clf__learning_rate': [0.01, 0.1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- 7. Train models with hyperparameter search ---\n",
    "best_models = {}\n",
    "\n",
    "for name, model_info in models.items():\n",
    "    print(f\"\\n{'-'*50}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        model_info['pipe'],\n",
    "        model_info['params'],\n",
    "        cv=cv,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best parameters: {grid.best_params_}\")\n",
    "    print(f\"Best CV score: {grid.best_score_:.4f}\")\n",
    "    \n",
    "    best_models[name] = grid.best_estimator_\n",
    "\n",
    "# --- 8. Evaluate models on test set ---\n",
    "results = pd.DataFrame(columns=['Model', 'ROC-AUC', 'Precision', 'Recall', 'F1-Score'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Add to results dataframe\n",
    "    results = pd.concat([results, pd.DataFrame({\n",
    "        'Model': [name],\n",
    "        'ROC-AUC': [roc_auc],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1-Score': [f1]\n",
    "    })], ignore_index=True)\n",
    "    \n",
    "    print(f\"\\n--- {name} Results ---\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Show final comparison table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(results.sort_values('ROC-AUC', ascending=False).reset_index(drop=True))\n",
    "\n",
    "# --- 9. (Optional) Feature importance from best model ---\n",
    "if 'RandomForest' in best_models:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FEATURE IMPORTANCE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    rf_model = best_models['RandomForest'].named_steps['clf']\n",
    "    preprocessor = best_models['RandomForest'].named_steps['pre']\n",
    "    \n",
    "    # Get feature names\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = rf_model.feature_importances_\n",
    "    \n",
    "    # Sort by importance\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    print(\"Top 15 most important features:\")\n",
    "    for i in range(min(15, len(feature_names))):\n",
    "        print(f\"{feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ee793",
   "metadata": {},
   "source": [
    "### For each algorithm explain which hyper-parameters you worked with and how you picked them. Bonus points if you apply the xgboost library.\n",
    "\n",
    "This project applied three different algorithms—logistic regression, random forest, and XGBoost(and the library for extra points)—to predict whether an NBA player would be selected to an All-NBA team based on season statistics. All models were implemented using scikit-learn and imbalanced-learn, with XGBoost handled using its dedicated Python API.\n",
    "\n",
    "Each model was placed into a pipeline that included preprocessing steps and a SMOTE sampler to address the significant class imbalance. For logistic regression, the hyperparameters tuned were the inverse regularization strength `C` and the solver (`liblinear` and `saga`). These were selected because they control the model’s flexibility and optimization strategy. GridSearchCV with 3-fold stratified cross-validation was used to search for the combination that gave the best ROC-AUC score.\n",
    "\n",
    "For the random forest model, key hyperparameters included the number of estimators (`n_estimators`), maximum depth of each tree (`max_depth`), and the minimum number of samples required to split a node (`min_samples_split`). These settings influence both model complexity and overfitting. A grid search was again performed to identify the best configuration, balancing depth and generalization.\n",
    "\n",
    "The third algorithm used was XGBoost, which was also the most flexible and powerful among the three. The main hyperparameters tuned included the number of boosting rounds (`n_estimators`), maximum tree depth (`max_depth`), and learning rate. These parameters govern how fast and deep the boosting process goes. Grid search was used here as well, and the model was evaluated using ROC-AUC to ensure good separation of the minority (All-NBA) class.\n",
    "\n",
    "All models were evaluated on a held-out test set using metrics such as precision, recall, F1-score, and ROC-AUC, with particular attention paid to recall given the importance of correctly identifying actual All-NBA players. This setup not only satisfies the assignment requirement of applying three distinct algorithms but also includes bonus implementation of XGBoost with appropriate tuning and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd4ce9",
   "metadata": {},
   "source": [
    "### A summary of your observations, and a separate optional section describing what you think may be a non-standard/novel thing you did in your experiments.\n",
    "\n",
    "##### Summary of Observations:\n",
    "After training and evaluating logistic regression, random forest, and XGBoost models on the All-NBA dataset, several patterns emerged. The most notable was that all models achieved very strong ROC-AUC scores (above 0.98), suggesting they were effective at distinguishing between All-NBA and non-All-NBA players. However, there were clear differences in how each model balanced precision and recall. Logistic regression had the highest recall at 94.3%, correctly identifying nearly all actual All-NBA players, but at the cost of precision—it incorrectly labeled many non-All-NBA players as positive. XGBoost offered the best balance overall, with a strong recall of 79.2% and a significantly higher precision of 55.3%, leading to the highest F1-score. Random forest trailed slightly behind XGBoost but still performed well in both recall and precision.\n",
    "\n",
    "\n",
    "The class imbalance (only 2.74% positive class) posed a major challenge. This was effectively handled using SMOTE within each model’s pipeline, which helped ensure that the models could actually learn from the limited All-NBA examples. Without this, the models would have likely defaulted to always predicting the negative class. The results highlight how critical it is to tune for recall in a task like this, where failing to recognize deserving All-NBA players would undermine the usefulness of the model.\n",
    "\n",
    "\n",
    "#### Optional: Non-standard/Novel Elements:\n",
    "A few elements of this project go slightly beyond a standard application. Most notably, SMOTE was integrated directly within each model’s cross-validation pipeline, ensuring oversampling was applied only during training folds and not leaked into validation, which could otherwise inflate performance. Another thoughtful detail was the normalization of positional data to core roles (G/F/C), which reduced noise during one-hot encoding and likely helped model consistency. Additionally, the feature importance analysis from the random forest model provided valuable interpretability. It revealed that advanced metrics like PER, VORP, WS/48, and BPM were among the most predictive of All-NBA selection, confirming that efficiency and overall impact metrics matter more than just raw box score stats. This kind of insight, derived from the model itself, adds meaningful depth to the analysis.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
